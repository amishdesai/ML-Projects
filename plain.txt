OpenAI released ChatGPT on November 30, 2022, and due to its success, 2023 became the year of AI chat apps. We saw similar offerings from competitors and even started building our own chat apps using Retrieval Augmented Generation (RAG). Now, as 2024 unfolds, the spotlight is shifting to AI Agents. These agents are set to do more for us than merely answering questions. They combine Large Language Models (LLMs) with specific tools (and memory) that enable them to perform various tasks. Think of it like using a screwdriver or a leaf-blower; AI agents employ digital tools such as fetching web URLs, reading unread Gmail, etc., to enhance their capabilities and assist us.

In this post, I’ll guide you through building an AI Agent from scratch using OpenAI models and Python, with a particular focus on the Langchain library. We’ll integrate this agent into a Slack app for seamless usability. Next, we’ll dockerize it, ensuring straightforward running and deployment. This step is essential before we start adding more custom tools specifically designed to handle some of our cognitive grunt-work. Here’s the link to the code. The best part? It should take you no more than 30 minutes to achieve this (provided you’re familiar with Python, Slack apps, and Docker), allowing you to create your own personal AI Agent!